# Kafka Integration Guide

> **Complete guide for Kafka messaging in CustomService**
>
> Generated by Copilot

## Overview

The CustomService template is integrated with **Apache Kafka** using the **shared infrastructure** from ExpenseVault.SharedLibrary. This enables:

- ✅ **Asynchronous event publishing** for created, updated, and deleted items
- ✅ **Distributed tracing** with correlation IDs and trace context propagation
- ✅ **Scalable message processing** with Kafka partitioning
- ✅ **Reliable delivery** with acknowledgments and retries
- ✅ **Event sourcing** capabilities for audit trails
- ✅ **Centralized Kafka infrastructure** shared across all services

## Architecture

### Topic Naming Convention

All integration events follow the standardized pattern:

```
{service}.{domain}.{event-type}
```

**CustomService topics:**
- `customservice.item.created` - Item creation events
- `customservice.item.updated` - Item update events
- `customservice.item.deleted` - Item deletion events

### Event Flow

```
┌─────────────┐         ┌──────────────┐         ┌─────────┐
│   Client    │────────▶│  CustomService│────────▶│  Kafka  │
│             │  HTTP   │   (Producer)  │  Event  │ Cluster │
└─────────────┘         └──────────────┘         └─────────┘
                                │                      │
                                │                      │
                        Persist to DB            ┌────▼────┐
                        + Invalidate Cache       │ Topics: │
                                                 │ - item. │
                                                 │   created│
                                                 │ - item. │
                                                 │   updated│
                                                 │ - item. │
                                                 │   deleted│
                                                 └─────────┘
                                                      │
                                                      ▼
                                            ┌──────────────────┐
                                            │ Other Services   │
                                            │ (Consumers)      │
                                            │ - Analytics      │
                                            │ - Notification   │
                                            │ - Audit          │
                                            └──────────────────┘
```

## Configuration

### appsettings.json

```json
{
  "Kafka": {
    "BootstrapServers": "localhost:9092",
    "ClientId": "customservice-producer",
    "EnableIdempotence": true,
    "Acks": -1,
    "MaxInFlight": 5,
    "MessageTimeoutMs": 30000,
    "RequestTimeoutMs": 30000,
    "RetryBackoffMs": 1000,
    "Topics": {}
  }
}
```

### Configuration Options

| Setting | Default | Description |
|---------|---------|-------------|
| `BootstrapServers` | `localhost:9092` | Kafka broker addresses (comma-separated) |
| `ClientId` | `customservice-producer` | Unique producer identifier |
| `EnableIdempotence` | `true` | Exactly-once delivery semantics |
| `Acks` | `-1` | Wait for all in-sync replicas to acknowledge |
| `MaxInFlight` | `5` | Max concurrent requests per connection |
| `MessageTimeoutMs` | `30000` | Message delivery timeout |
| `RequestTimeoutMs` | `30000` | Request timeout |
| `RetryBackoffMs` | `1000` | Retry delay in milliseconds |
| `Topics` | `{}` | Custom topic name mappings (optional) |

### Environment-Specific Configuration

**Development (appsettings.Development.json):**
```json
{
  "Kafka": {
    "BootstrapServers": "localhost:9092"
  }
}
```

**Production (appsettings.Production.json):**
```json
{
  "Kafka": {
    "BootstrapServers": "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092",
    "ClientId": "customservice-prod-producer",
    "EnableIdempotence": true,
    "Acks": -1
  }
}
```

## Docker Setup

### Start Infrastructure

**1. Start shared infrastructure (first time):**

```bash
cd ExpenseVault.SharedLibrary
docker-compose up -d  # Redis, Kafka, Zookeeper, Kafka UI, Jaeger, Seq
cd ..
```

**2. Start CustomService database:**

```bash
docker-compose up -d  # PostgreSQL for CustomService
```

**3. Check service status:**

```bash
# Check shared infrastructure
cd ExpenseVault.SharedLibrary
docker-compose ps
cd ..

# Check CustomService database
docker-compose ps
```

**4. View logs:**

```bash
# Kafka logs (from SharedLibrary)
cd ExpenseVault.SharedLibrary
docker-compose logs -f ev-kafka
cd ..
```

### Services Available

| Service | Port | Location | Description |
|---------|------|----------|-------------|
| **PostgreSQL (CustomService)** | 5434 | CustomService | Service-specific database |
| **Redis (Shared)** | 6379 | SharedLibrary | Caching (password: redis123) |
| **Zookeeper (Shared)** | 2181 | SharedLibrary | Kafka coordination |
| **Kafka (Shared)** | 9092 (external)<br>29092 (internal) | SharedLibrary | Message broker |
| **Kafka UI (Shared)** | 8080 | SharedLibrary | Web UI for Kafka management |
| **Jaeger (Shared)** | 16686 | SharedLibrary | Distributed tracing |
| **Seq (Shared)** | 5342 | SharedLibrary | Centralized logging |

### Access Kafka UI

Open your browser to: **http://localhost:8080**

Features:
- View topics and messages
- Monitor consumer groups
- Check broker health
- Inspect message content

## Integration Events

### CustomItemCreatedEvent

Published when a new item is created.

**Topic:** `customservice.item.created`

**Schema:**
```json
{
  "eventId": "3fa85f64-5717-4562-b3fc-2c963f66afa6",
  "timestamp": "2025-11-30T10:30:00Z",
  "eventType": "created",
  "eventVersion": "1.0",
  "sourceService": "customservice",
  "correlationId": "abc123-def456",
  "customItemId": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
  "name": "Sample Item",
  "description": "Item description",
  "userId": "550e8400-e29b-41d4-a716-446655440000",
  "categoryId": "660e8400-e29b-41d4-a716-446655440000",
  "status": "Active"
}
```

**Partitioning:** By `userId` for ordered events per user

### CustomItemUpdatedEvent

Published when an item is updated.

**Topic:** `customservice.item.updated`

**Schema:**
```json
{
  "eventId": "4fa85f64-5717-4562-b3fc-2c963f66afa7",
  "timestamp": "2025-11-30T11:00:00Z",
  "eventType": "updated",
  "eventVersion": "1.0",
  "sourceService": "customservice",
  "correlationId": "abc123-def456",
  "customItemId": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
  "name": "Updated Item Name",
  "description": "Updated description",
  "userId": "550e8400-e29b-41d4-a716-446655440000",
  "status": "Active",
  "modifiedBy": "user@example.com"
}
```

### CustomItemDeletedEvent

Published when an item is soft-deleted.

**Topic:** `customservice.item.deleted`

**Schema:**
```json
{
  "eventId": "5fa85f64-5717-4562-b3fc-2c963f66afa8",
  "timestamp": "2025-11-30T12:00:00Z",
  "eventType": "deleted",
  "eventVersion": "1.0",
  "sourceService": "customservice",
  "correlationId": "abc123-def456",
  "customItemId": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
  "userId": "550e8400-e29b-41d4-a716-446655440000",
  "name": "Deleted Item",
  "deletedBy": "user@example.com"
}
```

## Usage Examples

### Publishing Events in Command Handlers

The CreateCustomItemCommandHandler demonstrates the pattern:

```csharp
public class CreateCustomItemCommandHandler : IRequestHandler<CreateCustomItemCommand, CustomItemDto>
{
    private readonly IMessagePublisher _messagePublisher;
    private readonly IHttpContextAccessor _httpContextAccessor;
    private readonly ILogger<CreateCustomItemCommandHandler> _logger;

    public async Task<CustomItemDto> Handle(CreateCustomItemCommand request, CancellationToken ct)
    {
        // 1. Perform business logic
        var item = CustomItem.Create(/* ... */);
        _context.Set<CustomItem>().Add(item);
        await _context.SaveChangesAsync(ct);

        // 2. Publish integration event
        await PublishCustomItemCreatedEventAsync(item, ct);

        return MapToDto(item);
    }

    private async Task PublishCustomItemCreatedEventAsync(CustomItem item, CancellationToken ct)
    {
        try
        {
            var correlationId = _httpContextAccessor.HttpContext?.Items["CorrelationId"]?.ToString();

            var integrationEvent = new CustomItemCreatedEvent
            {
                CustomItemId = item.Id,
                Name = item.Name,
                Description = item.Description,
                UserId = item.UserId,
                CategoryId = item.CategoryId,
                Status = item.Status.ToString(),
                CorrelationId = correlationId
            };

            await _messagePublisher.PublishIntegrationEventAsync(integrationEvent, ct);
            
            _logger.LogInformation(
                "Published CustomItemCreatedEvent for item {CustomItemId} to topic {Topic}",
                item.Id,
                integrationEvent.Topic);
        }
        catch (Exception ex)
        {
            // Event publishing is non-critical - don't fail the operation
            _logger.LogError(ex, "Failed to publish event for item {CustomItemId}", item.Id);
        }
    }
}
```

### Creating Custom Integration Events

1. **Create event class** inheriting from `IntegrationEventBase`:

```csharp
using ExpenseVault.Common.Messaging;

public record CustomNotificationEvent : IntegrationEventBase
{
    public Guid UserId { get; init; }
    public string Message { get; init; } = string.Empty;
    
    public override string EventType => "notification";
    public override string SourceService => "customservice";
    protected override string GetDomain() => "notification";
    public override string GetPartitionKey() => UserId.ToString();
}
```

2. **Publish the event:**

```csharp
var notificationEvent = new CustomNotificationEvent
{
    UserId = userId,
    Message = "Custom notification message",
    CorrelationId = correlationId
};

await _messagePublisher.PublishIntegrationEventAsync(notificationEvent, ct);
```

## Monitoring & Debugging

### View Messages in Kafka UI

1. Navigate to **http://localhost:8080**
2. Select cluster: **customservice-cluster**
3. Click **Topics**
4. Select a topic (e.g., `customservice.item.created`)
5. View messages, partitions, and consumer groups

### Kafka CLI Commands

**List topics:**
```bash
docker exec customservice-kafka kafka-topics --list --bootstrap-server localhost:9092
```

**Describe a topic:**
```bash
docker exec customservice-kafka kafka-topics --describe \
  --topic customservice.item.created \
  --bootstrap-server localhost:9092
```

**Consume messages:**
```bash
docker exec customservice-kafka kafka-console-consumer \
  --topic customservice.item.created \
  --from-beginning \
  --bootstrap-server localhost:9092
```

**Check consumer groups:**
```bash
docker exec customservice-kafka kafka-consumer-groups --list \
  --bootstrap-server localhost:9092
```

### Logs and Tracing

Events include distributed tracing headers:

```
[12:34:56 INF] [correlation-id-123] [trace-id-456] Published CustomItemCreatedEvent for item 7c9e6679... to topic customservice.item.created
```

Check logs:
```bash
# Application logs
cat logs/log-*.json | grep "CustomItemCreatedEvent"

# Docker logs
docker-compose logs -f customservice-api
```

## Testing

### Unit Tests

Mock `IMessagePublisher` in your tests:

```csharp
[Fact]
public async Task Handle_ShouldPublishIntegrationEvent()
{
    // Arrange
    var messagePublisher = Substitute.For<IMessagePublisher>();
    var handler = new CreateCustomItemCommandHandler(
        context,
        cache,
        messagePublisher,
        httpContextAccessor,
        logger);

    // Act
    await handler.Handle(command, CancellationToken.None);

    // Assert
    await messagePublisher.Received(1).PublishIntegrationEventAsync(
        Arg.Is<CustomItemCreatedEvent>(e => e.CustomItemId == expectedId),
        Arg.Any<CancellationToken>());
}
```

### Integration Tests

Use Testcontainers for Kafka:

```csharp
public class KafkaIntegrationTests : IAsyncLifetime
{
    private KafkaContainer _kafkaContainer;
    
    public async Task InitializeAsync()
    {
        _kafkaContainer = new KafkaBuilder()
            .WithImage("confluentinc/cp-kafka:7.6.0")
            .Build();
        
        await _kafkaContainer.StartAsync();
    }
    
    [Fact]
    public async Task PublishEvent_ShouldBeReceivedByConsumer()
    {
        // Test implementation
    }
}
```

## Best Practices

### ✅ Do's

1. **Always include CorrelationId** for distributed tracing
2. **Use try-catch around event publishing** - don't fail business operations
3. **Log event publishing** with structured logging
4. **Partition by meaningful keys** (UserId, TenantId) for ordering
5. **Version your events** for backward compatibility
6. **Make events immutable** (use `record` types)
7. **Include all necessary context** in events (no database lookups in consumers)

### ❌ Don'ts

1. **Don't fail business operations** if event publishing fails
2. **Don't include sensitive data** in events (passwords, tokens)
3. **Don't make events too large** (keep under 1MB)
4. **Don't rely on immediate delivery** - Kafka is eventually consistent
5. **Don't create circular dependencies** between services
6. **Don't change event schemas** without versioning

## Troubleshooting

### Issue: Kafka not connecting

**Check broker status:**
```bash
docker-compose ps kafka
docker-compose logs kafka
```

**Verify network:**
```bash
docker network ls
docker network inspect customservice-network
```

### Issue: Events not appearing in topics

**Check producer logs:**
```bash
cat logs/log-*.json | grep -i "kafka\|event"
```

**Verify topic creation:**
```bash
docker exec customservice-kafka kafka-topics --list --bootstrap-server localhost:9092
```

### Issue: Performance degradation

**Check producer metrics:**
- Message send time
- Request queue time
- Acknowledgment wait time

**Tune configuration:**
- Increase `MaxInFlight` for throughput
- Adjust `MessageTimeoutMs` for latency
- Enable compression for large messages

## Production Considerations

### High Availability

```json
{
  "Kafka": {
    "BootstrapServers": "broker1:9092,broker2:9092,broker3:9092",
    "EnableIdempotence": true,
    "Acks": -1,
    "MaxInFlight": 5
  }
}
```

### Security

- Enable SSL/TLS for encrypted communication
- Configure SASL authentication
- Use ACLs for topic authorization
- Rotate credentials regularly

### Monitoring

Integrate with:
- **Prometheus** for Kafka metrics
- **Grafana** for dashboards
- **Jaeger/Zipkin** for distributed tracing
- **ELK Stack** for log aggregation

## Migration from Template

When customizing this template for your service:

1. **Update service name** in events:
   ```csharp
   public override string SourceService => "yourservice"; // Change from "customservice"
   ```

2. **Update ClientId** in configuration:
   ```json
   {
     "Kafka": {
       "ClientId": "yourservice-producer"
     }
   }
   ```

3. **Define your domain events** in `Application/Events/`

4. **Update docker-compose** container names if needed

## Resources

- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Confluent Platform](https://docs.confluent.io/)
- [ExpenseVault Messaging README](../ExpenseVault.SharedLibrary/ExpenseVault.Common/Messaging/README.md)
- [Integration Events Pattern](https://microservices.io/patterns/data/event-driven-architecture.html)

---

**Generated by Copilot**

**Last Updated:** November 30, 2025
